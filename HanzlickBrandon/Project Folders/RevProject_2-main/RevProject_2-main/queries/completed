-- 1. Which store has maximum sales?

spark.sql("use wmdata")
val df = spark.sql("select * from sales")
val dfq1 = df.groupBy("store")
                        .agg(
                                sum("weekly_sales").cast("decimal(32,2)").as("total_sales"),
                                avg("temperature").cast("decimal(32,2)").as("avg_temp"),
                                avg("fuel_price").cast("decimal(32,2)").as("avg_fuel_price"),
                                avg("unemployment").cast("decimal(32,2)").as("avg_unemployment")
                        )
val dfq1a = dfq1.orderBy(desc("total_sales")).limit(10)
val dfq1b = dfq1.orderBy(asc("total_sales")).limit(10)

dfq1a.show
+-----+------------+--------+--------------+----------------+
|store| total_sales|avg_temp|avg_fuel_price|avg_unemployment|
+-----+------------+--------+--------------+----------------+
|   20|301397792.46|   55.45|          3.42|            7.37|
|    4|299543953.38|   62.25|          3.22|            5.97|
|   14|288999911.34|   57.79|          3.42|            8.65|
|   13|286517703.80|   53.70|          3.29|            7.00|
|    2|275382440.98|   68.22|          3.22|            7.62|
|   10|271617713.89|   72.24|          3.58|            8.36|
|   27|253855916.88|   57.31|          3.58|            8.00|
|    6|223756130.64|   69.70|          3.22|            6.61|
|    1|222402808.85|   68.31|          3.22|            7.61|
|   39|207445542.47|   70.60|          3.22|            7.87|
+-----+------------+--------+--------------+----------------+

dfq1b.show
+-----+-----------+--------+--------------+----------------+
|store|total_sales|avg_temp|avg_fuel_price|avg_unemployment|
+-----+-----------+--------+--------------+----------------+
|   33|37160221.96|   76.40|          3.58|            8.53|
|   44|43293087.84|   53.70|          3.29|            6.74|
|    5|45475688.90|   69.41|          3.22|            6.30|
|   36|53412214.97|   71.16|          3.20|            7.87|
|   38|55159626.42|   70.26|          3.61|           13.12|
|    3|57586735.07|   71.43|          3.22|            7.18|
|   30|62716885.12|   68.85|          3.22|            7.62|
|   37|74202740.32|   71.16|          3.22|            7.87|
|   16|74252425.40|   45.03|          3.24|            6.48|
|   29|77141554.31|   54.90|          3.44|            9.81|
+-----+-----------+--------+--------------+----------------+




-- 2. Which store/s has a good quarterly growth rate in Q3â€™2012?

spark.sql("use wmdata")
val df = spark.sql("select * from sales")
df1 = df.filter(year(col("date")) === 2012 and quarter(col("date")) === 3 )
val df2 = df1.groupBy("store")
	.agg(
		sum("weekly_sales").cast("decimal(38,2)").as("total_sales"), 
		avg("temperature").cast("decimal(4,2)").as("avg_temp"), 
		avg("fuel_price").cast("decimal(38,3)").as("avg_fuel_price") 
	)

df2.orderBy(desc("total_sales")).limit(10).show
+-----+-----------+--------+--------------+
|store|total_sales|avg_temp|avg_fuel_price|
+-----+-----------+--------+--------------+
|    4|27796792.46|   77.63|         3.499|
|   20|26891526.98|   71.50|         3.768|
|   13|26421259.30|   76.20|         3.628|
|    2|24303354.86|   82.40|         3.521|
|   10|23037258.76|   84.99|         3.867|
|   27|22307711.41|   74.58|         3.929|
|   14|21187560.65|   74.73|         3.768|
|   39|20715116.23|   80.84|         3.521|
|    1|20253947.78|   80.06|         3.521|
|    6|20167312.24|   82.05|         3.521|
+-----+-----------+--------+--------------+




-- 3. Provide a monthly and semester view of sales in units and give insights?

spark.sql("use wmdata")
val df = spark.sql("select * from sales")
val df1 = df.withColumn("month", month(col("date")))
val df2 = df1.groupBy("store", "month").agg( sum("weekly_sales").cast("decimal(38,2)").as("monthly_sales"))

df3.orderBy("store", "month").limit(10).show
+-----+-----+-------------+
|store|month|monthly_sales|
+-----+-----+-------------+
|    1|    1|  11203741.49|
|    1|    2|  19505306.58|
|    1|    3|  20380666.86|
|    1|    4|  21623140.34|
|    1|    5|  18505332.90|
|    1|    6|  20299636.04|
|    1|    7|  20706084.02|
|    1|    8|  20118558.27|
|    1|    9|  19331717.78|
|    1|   10|  19468556.79|
+-----+-----+-------------+



-- 4. Which store has the maximum standard deviation, i.e., the sales vary a lot.

spark.sql("use wmdata")
val df = spark.sql("select * from sales")
val df1 = df.groupBy("store").agg( stddev_pop("weekly_sales").cast("decimal(38,2)").as("std_dev"))

df1.orderBy(desc("std_dev")).limit(10).show
+-----+---------+
|store|  std_dev|
+-----+---------+
|   14|316457.62|
|   10|301203.35|
|   20|274934.18|
|    4|265269.04|
|   13|264577.02|
|   23|248913.12|
|   27|239089.75|
|    2|236851.17|
|   39|216704.75|
|    6|211781.45|
+-----+---------+

df1.orderBy(asc("std_dev")).limit(10).show

+-----+--------+
|store| std_dev|
+-----+--------+
|   37|21760.97|
|   30|22729.77|
|   33|24048.40|
|   44|24676.10|
|    5|37605.78|
|   43|40456.21|
|   38|42618.37|
|    3|46157.39|
|   42|50086.87|
|   36|60512.48|
+-----+--------+

















